# -*- coding: utf-8 -*-
"""CNN_Tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UNaZE9bC_zSV3J0cG5sJlZ1tB9asxn7n

##### Download the datasets
"""

import zipfile
!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip

t = zipfile.ZipFile("pizza_steak.zip","r")
t.extractall()
t.close()

!ls pizza_steak/test/pizza

"""# View the datasets"""

import matplotlib.pyplot as plt
import random as rd
import numpy as np
import os

train_dir = "pizza_steak/train"
path1 = "pizza_steak/train/pizza"
path2 = "pizza_steak/train/steak"

for  dirpath,dirnames,filenames in os.walk("pizza_steak"):
  print(f"No of files present in {dirpath} is {len(filenames)}")

import pathlib
data_dir = pathlib.Path("pizza_steak/train")
class_names  = np.array(sorted([files.name for files in data_dir.glob('*')]))
class_names

"""**Data Visualization**"""

import matplotlib.image as mpimg

def viewData(path1, path2):
  plt.figure(figsize=(7,13))
  plt.subplot(1,2,1)
  path1 = path1 + "/" + rd.sample(os.listdir(f"{path1}"),1)[0]
  plt.title(f"{path1}", fontsize=7)
  sel1 = mpimg.imread(path1)
  plt.xlabel(f"Dim {sel1.shape}")
  plt.imshow(sel1)

  plt.subplot(1,2,2)
  path2  = path2 + "/" + rd.sample(os.listdir(f"{path2}"),1)[0]
  plt.title(f"{path2}", fontsize=7)
  sel2 = mpimg.imread(path2)
  plt.xlabel(f"Dim {sel2.shape}")
  plt.imshow(sel2)

viewData(path1 = path1, path2 = path2)

def imgData(_path):
  return mpimg.imread(f"{_path}/" + os.listdir(f"{_path}")[0])

imgData(path2)

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.activations import relu
from tensorflow.keras.metrics import Accuracy
from tensorflow.keras.layers import Dense, MaxPool2D, Conv2D
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Input

"""#### **Model 1**"""

train_path = "pizza_steak/train"
test_path = "pizza_steak/test"

# Set seed
tf.random.set_seed(42)

train_datagen = ImageDataGenerator(rescale=1/255.)
valid_datagen = ImageDataGenerator(rescale=1/255.)

train_data = train_datagen.flow_from_directory(train_path,
                                              batch_size = 32,
                                              target_size = (224,224),
                                              class_mode = "binary",
                                              seed=42)

valid_data = valid_datagen.flow_from_directory(test_path,
                                              batch_size=32,
                                              target_size=(224,224),
                                              class_mode="binary",
                                              seed=42)

"""##### Code for the Model



"""

tf.random.set_seed(42)

model1 = Sequential([
    Conv2D(filters=10,
           kernel_size=(3,3),
           activation="relu",
           input_shape=(224,224,3)),
    Conv2D(filters=10,
           kernel_size=(3,3),
           activation="relu"), # No need to mention the shape (if you want then 224-2, 224-2,10)
    MaxPool2D(pool_size=2,
              padding="valid"), # Valid = no padding
    Conv2D(filters=10,
           kernel_size=(3,3),
           activation="relu"),
    Conv2D(filters=10,
           kernel_size=3,
           activation="relu"),
    MaxPool2D(pool_size=(2,2),
              padding="valid"), # Default
  Flatten(),
  Dense(1,activation="sigmoid")  # max(0,x)
    ])


model1.compile(loss="binary_crossentropy",
               optimizer = tf.optimizers.Adam(),
               metrics=["accuracy"])

history1 =model1.fit(
    train_data, # Normalized Data
    epochs = 5,
    steps_per_epoch = len(train_data),
    validation_data = valid_data,
    validation_steps=len(valid_data)
)

len(train_data)* 32

model1.summary()

import pandas as pd
pd.DataFrame(history1.history).plot(title="Model 1")

tf.random.set_seed(42)

data_gen1 = ImageDataGenerator(rescale=1/255.,
                               rotation_range = 20,
                               shear_range=0.2,
                               width_shift_range=0.2,
                               height_shift_range=0.2)
train_data1 = data_gen1.flow_from_directory(train_path,
                                            batch_size = 32,
                                            target_size = (224,224),
                                            class_mode = "binary",
                                            seed=42)
model2 = Sequential([
    Conv2D(filters=10,
           kernel_size=(3,3),
           activation="relu",  # max(0,x)
           input_shape=(224,224,3)),
    Conv2D(filters=10,
           kernel_size=(3,3),
           activation="relu"), # No need to mention the shape (if you want then 224-2, 224-2,10)
    MaxPool2D(pool_size=2,
              padding="valid"), # Valid = no padding
    Conv2D(filters=10,
           kernel_size=(3,3),
           activation="relu"),
    Conv2D(filters=10,
           kernel_size=3,
           activation="relu"),
    MaxPool2D(pool_size=(2,2),
              padding="valid"), # Default
  Flatten(),
  Dense(1,activation="sigmoid")
    ])


model2.compile(loss="binary_crossentropy",
               optimizer = tf.optimizers.Adam(),
               metrics=["accuracy"])

history2 =model2.fit(
    train_data1, # Normalized Data
    epochs = 5,
    steps_per_epoch = len(train_data1),
    validation_data = valid_data,
    validation_steps=len(valid_data)
)

model2.summary()

pd.DataFrame(history2.history).plot(title="Model -2")

"""## Binary Classification for the food vision

"""

tf.random.set_seed(42)

# Adding More layers to increase the throughput
model3 = Sequential([
    Flatten(input_shape=(224,224,3)),
    Dense(100,activation="relu"),
    Dense(100,activation="relu"),
    Dense(100,activation="relu"),
    Dense(1,activation="sigmoid")
])

model3.compile(loss="binary_crossentropy",
               optimizer=tf.keras.optimizers.Adam(),
               metrics=["accuracy"])

history3 = model3.fit(train_data,
           epochs=5,
           batch_size=32,
           steps_per_epoch=len(train_data),
           validation_data = valid_data,
           validation_steps = len(valid_data))

model3.summary() # has high trainable params but performing worse than our mode1

#Plotting
pd.DataFrame(history3.history).plot(title="Model 3")

## Visualize
img1 = viewData(path1, path2)

images,labels = train_data.next()

plt.imshow(images[10]), labels[10]

"""**Labels**

**0 - Pizza**

**1 - Steak**
"""

images[0].shape

# Model - 4
tf.random.set_seed(42)

model4 = Sequential([
    Conv2D(filters=10, kernel_size=3, activation="relu", input_shape=(224,224,3)),
    Conv2D(filters=10, kernel_size=3, activation="relu"),
    Conv2D(filters=10, kernel_size=3, activation="relu"),
    Flatten(),
    Dense(1, activation="sigmoid")
])

model4.compile(loss=tf.keras.losses.binary_crossentropy,
               optimizer= tf.keras.optimizers.Adam(),
               metrics=["accuracy"])


history4 = model4.fit(train_data,
           epochs=5,
           steps_per_epoch=len(train_data),
           validation_data = valid_data,
           validation_steps = len(valid_data))

model4.summary()

pd.DataFrame(history4.history).plot(title="Model4")

"""**Model is learning good but performance on train data is not satisfactory**

**Validate loss** is increasing leading to **Overfitting** of the model
"""

def plotThroughput(history):
  plt.figure(figsize=(17,5))
  plt.subplot(1,2,1)
  plt.title("Accuracy")
  plt.plot(history.history["accuracy"],c="b")
  plt.plot(history.history['val_accuracy'], c="g")
  plt.xlabel('Epochs')
  plt.legend();

  plt.subplot(1,2,2)
  plt.title("Loss")
  plt.plot(history.history['loss'], c='b')
  plt.plot(history.history['val_loss'], c='g')
  plt.xlabel("Epochs")
  plt.legend();

plotThroughput(history4)
# plt.plot(history4.history['accuracy'])
# plt.plot( history4.history['val_accuracy'])
# plt.legend()

"""**Let's Add MaxPool2D Layer**

## Model 5
"""

tf.random.set_seed(42)

model5 = Sequential([
    Conv2D(filters=10, kernel_size=3, activation="relu", input_shape=(224,224,3)),
    MaxPool2D(pool_size=2),
    Conv2D(filters=10, kernel_size=3, activation="relu"),
    MaxPool2D(),
    Conv2D(filters=10, kernel_size=3, activation="relu"),
    MaxPool2D(),
    Flatten(),
    Dense(1, activation="sigmoid")
])

model5.compile(loss=tf.keras.losses.binary_crossentropy,
                optimizer = "adam",
                metrics=["accuracy"])

history5 = model5.fit(train_data,
           epochs=5,
           steps_per_epoch=len(train_data),
           validation_data = valid_data,
           validation_steps = len(valid_data))

model5.summary()

plotThroughput(history5)

"""- The loss is still high on training dataset.
- Model is performing worst in training dataset but better in validation dataset

## Use Data Augmentation to overcome **Overfitting**
"""

data_augment = ImageDataGenerator(rescale=1/255.,
                                  rotation_range = 20,
                                  shear_range=0.2,
                                  zoom_range=0.2,
                                  width_shift_range=0.2,
                                  height_shift_range=0.2,
                                  horizontal_flip=True)

augdata_train = data_augment.flow_from_directory(
                                  train_path,
                                  target_size=(224,224),
                                  color_mode="rgb",
                                  classes=None ,
                                  shuffle=True,
                                  seed=42,
                                  class_mode="binary",
                                  batch_size=32

)

augdata_valid = data_augment.flow_from_directory(
                                  test_path,
                                  target_size=(224,224),
                                  color_mode="rgb",
                                  classes=None,
                                  shuffle=True,
                                  seed=42,
                                  class_mode="binary",
                                  batch_size=32
)

images, labels = augdata_train.next()

import random
def view_random_image(images):
    choice = random.randint(0, len(images))
    plt.imshow(images[choice])

view_random_image(images)

"""### Model 6

"""

tf.random.set_seed(42)

model6  = Sequential([
        Conv2D(filters=4, kernel_size=3, activation="relu", input_shape=(224,224,3)),
        Conv2D(4,3,activation="relu"),
        MaxPool2D(pool_size=2),
        Conv2D(4,3 ,activation='relu'),
        Conv2D(4,3,activation="relu"),
        MaxPool2D(),
        Flatten(),
        Dense(1, activation="sigmoid")
])

model6.compile(loss=tf.keras.losses.binary_crossentropy,
               optimizer = "adam",
               metrics=["accuracy"])

history6 = model6.fit(augdata_train,
                      epochs=5,
                      steps_per_epoch=len(augdata_train),
                      validation_data = augdata_valid,
                      validation_steps = len(augdata_valid))

model6.summary() # Trainable params is less i.e. equal to model1

plotThroughput(history6)

## Looks Nice, Let's predict

from PIL import Image
def prepareData(img_path):
  img = Image.open(img_path).convert("RGB")
  img = tf.image.resize(img, size=(224,224))
  img = img/255.
  plt.imshow(img)
  return img

samp_ = prepareData("sample.jpeg")
samp = tf.expand_dims(samp_, axis=0) # Adding 1 layer

samp.shape

pred = int(tf.round(model6.predict(samp)[0][0]))

plt.imshow(samp_)
plt.title(f"Predicted => {class_names[pred]}")

"""**Create a function to randomly select an image & predict**"""

import random as rd

def predict_plot(model, path="pizza_steak/test/"):

  dir_choice  =  os.listdir(path)
  path += dir_choice[rd.randint(0,1)] + "/"
  img_choice = os.listdir(path)
  path += img_choice[rd.randint(0,len(img_choice)-1)]
  samp_ = prepareData(path)
  samp = tf.expand_dims(samp_, axis=0)
  pred_ = int(tf.round(model.predict(samp)[0][0]))
  plt.title(f"Predicted {dir_choice[pred_]}")
  plt.imshow(samp_)

predict_plot(model6)

predict_plot(model6)

